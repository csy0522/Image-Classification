{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Data_Reader import load_mnist\n",
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PATH = \"../data\"        # Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ANN import *\n",
    "\n",
    "'''\n",
    "Artifitial Neural Network\n",
    "\n",
    "This is a Neural Network with 1 hidden layer\n",
    "Inputs are 60000 images with 784 pixels\n",
    "Output has 10 categories\n",
    "The prediction is based on the percentage of predictions\n",
    "The highest percentages among all the prediction is the predicted answer.\n",
    "'''\n",
    "### Hyper Parameters used to adjust the result ###\n",
    "hiddens = [[20,],[80,],[300,]] # <---- Hyperparameters (Hidden Layer Parameters)\n",
    "learning_rate = [0.001, 0.0001, 0.00001] # <---- Hyperparameters (Learning Rate)\n",
    "activation = 'sigmoid' # <---- Hyperparameters (Activation Function)\n",
    "learning_rate_descent = 1 # <---- Hyperparameters (Learning rate decay)\n",
    "epoch = 10 # <---- Hyperparameters (Epochs)\n",
    "batch_size = 6000 # <---- Hyperparameters (Batch Size)\n",
    "\n",
    "### Data ###\n",
    "X,y = get_data(PATH, kind='train', norm_size=255)\n",
    "val_X,val_y = get_validation_data(X,y,0.2)      ### use 20% of the training data for validation ###\n",
    "test_X,test_y = get_data(PATH, kind='t10k', norm_size=255)\n",
    "\n",
    "### Neural Network Model ###\n",
    "ann = ANN(X.shape[1],hiddens[1],10,activation)\n",
    "ann.__initialize_weights_biases__()     \n",
    "ann.__initialize_hyperparameters__(\n",
    "  learning_rate[1],\n",
    "  learning_rate_descent,\n",
    "  epoch,\n",
    "  batch_size)\n",
    "ann.__train__(X,y)\n",
    "\n",
    "ann.__test__(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 12000 samples\n",
      "Epoch 1/600\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 2.4443 - accuracy: 0.1002 - val_loss: 2.3992 - val_accuracy: 0.1010\n",
      "Epoch 2/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.3731 - accuracy: 0.1186 - val_loss: 2.3502 - val_accuracy: 0.1458\n",
      "Epoch 3/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.3355 - accuracy: 0.1658 - val_loss: 2.3226 - val_accuracy: 0.1767\n",
      "Epoch 4/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.3136 - accuracy: 0.1865 - val_loss: 2.3057 - val_accuracy: 0.1891\n",
      "Epoch 5/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.2997 - accuracy: 0.1946 - val_loss: 2.2944 - val_accuracy: 0.1926\n",
      "Epoch 6/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.2901 - accuracy: 0.1995 - val_loss: 2.2864 - val_accuracy: 0.1983\n",
      "Epoch 7/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.2831 - accuracy: 0.2024 - val_loss: 2.2801 - val_accuracy: 0.2033\n",
      "Epoch 8/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.2775 - accuracy: 0.2077 - val_loss: 2.2750 - val_accuracy: 0.2148\n",
      "Epoch 9/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.2728 - accuracy: 0.2291 - val_loss: 2.2706 - val_accuracy: 0.2386\n",
      "Epoch 10/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.2686 - accuracy: 0.2535 - val_loss: 2.2666 - val_accuracy: 0.2642\n",
      "Epoch 11/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.2648 - accuracy: 0.2726 - val_loss: 2.2628 - val_accuracy: 0.2836\n",
      "Epoch 12/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.2611 - accuracy: 0.2939 - val_loss: 2.2592 - val_accuracy: 0.3058\n",
      "Epoch 13/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.2575 - accuracy: 0.3188 - val_loss: 2.2557 - val_accuracy: 0.3303\n",
      "Epoch 14/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.2541 - accuracy: 0.3436 - val_loss: 2.2522 - val_accuracy: 0.3597\n",
      "Epoch 15/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.2506 - accuracy: 0.3763 - val_loss: 2.2488 - val_accuracy: 0.3886\n",
      "Epoch 16/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.2472 - accuracy: 0.3964 - val_loss: 2.2454 - val_accuracy: 0.4110\n",
      "Epoch 17/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.2437 - accuracy: 0.4180 - val_loss: 2.2419 - val_accuracy: 0.4269\n",
      "Epoch 18/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.2402 - accuracy: 0.4319 - val_loss: 2.2384 - val_accuracy: 0.4385\n",
      "Epoch 19/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.2367 - accuracy: 0.4475 - val_loss: 2.2350 - val_accuracy: 0.4490\n",
      "Epoch 20/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.2332 - accuracy: 0.4542 - val_loss: 2.2314 - val_accuracy: 0.4568\n",
      "Epoch 21/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.2297 - accuracy: 0.4617 - val_loss: 2.2279 - val_accuracy: 0.4628\n",
      "Epoch 22/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.2261 - accuracy: 0.4668 - val_loss: 2.2243 - val_accuracy: 0.4702\n",
      "Epoch 23/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.2225 - accuracy: 0.4745 - val_loss: 2.2207 - val_accuracy: 0.4780\n",
      "Epoch 24/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.2188 - accuracy: 0.4799 - val_loss: 2.2171 - val_accuracy: 0.4828\n",
      "Epoch 25/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.2152 - accuracy: 0.4870 - val_loss: 2.2134 - val_accuracy: 0.4901\n",
      "Epoch 26/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.2114 - accuracy: 0.4944 - val_loss: 2.2097 - val_accuracy: 0.4947\n",
      "Epoch 27/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.2077 - accuracy: 0.5009 - val_loss: 2.2059 - val_accuracy: 0.4992\n",
      "Epoch 28/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.2039 - accuracy: 0.5044 - val_loss: 2.2021 - val_accuracy: 0.5035\n",
      "Epoch 29/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 2.2000 - accuracy: 0.5082 - val_loss: 2.1982 - val_accuracy: 0.5078\n",
      "Epoch 30/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.1961 - accuracy: 0.5152 - val_loss: 2.1944 - val_accuracy: 0.5117\n",
      "Epoch 31/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.1922 - accuracy: 0.5178 - val_loss: 2.1904 - val_accuracy: 0.5175\n",
      "Epoch 32/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.1882 - accuracy: 0.5203 - val_loss: 2.1864 - val_accuracy: 0.5217\n",
      "Epoch 33/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.1842 - accuracy: 0.5261 - val_loss: 2.1824 - val_accuracy: 0.5254\n",
      "Epoch 34/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.1801 - accuracy: 0.5293 - val_loss: 2.1783 - val_accuracy: 0.5296\n",
      "Epoch 35/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.1760 - accuracy: 0.5336 - val_loss: 2.1742 - val_accuracy: 0.5324\n",
      "Epoch 36/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.1718 - accuracy: 0.5359 - val_loss: 2.1700 - val_accuracy: 0.5349\n",
      "Epoch 37/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.1676 - accuracy: 0.5394 - val_loss: 2.1658 - val_accuracy: 0.5379\n",
      "Epoch 38/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.1633 - accuracy: 0.5432 - val_loss: 2.1615 - val_accuracy: 0.5404\n",
      "Epoch 39/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.1590 - accuracy: 0.5427 - val_loss: 2.1572 - val_accuracy: 0.5444\n",
      "Epoch 40/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.1546 - accuracy: 0.5468 - val_loss: 2.1528 - val_accuracy: 0.5462\n",
      "Epoch 41/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.1501 - accuracy: 0.5480 - val_loss: 2.1484 - val_accuracy: 0.5492\n",
      "Epoch 42/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.1457 - accuracy: 0.5511 - val_loss: 2.1439 - val_accuracy: 0.5522\n",
      "Epoch 43/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.1411 - accuracy: 0.5529 - val_loss: 2.1394 - val_accuracy: 0.5548\n",
      "Epoch 44/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 2.1365 - accuracy: 0.5574 - val_loss: 2.1348 - val_accuracy: 0.5559\n",
      "Epoch 45/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.1319 - accuracy: 0.5584 - val_loss: 2.1302 - val_accuracy: 0.5579\n",
      "Epoch 46/600\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 2.1272 - accuracy: 0.5605 - val_loss: 2.1255 - val_accuracy: 0.5593\n",
      "Epoch 47/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.1225 - accuracy: 0.5613 - val_loss: 2.1207 - val_accuracy: 0.5608\n",
      "Epoch 48/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.1177 - accuracy: 0.5631 - val_loss: 2.1159 - val_accuracy: 0.5633\n",
      "Epoch 49/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.1128 - accuracy: 0.5630 - val_loss: 2.1111 - val_accuracy: 0.5647\n",
      "Epoch 50/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.1079 - accuracy: 0.5672 - val_loss: 2.1062 - val_accuracy: 0.5653\n",
      "Epoch 51/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.1029 - accuracy: 0.5674 - val_loss: 2.1012 - val_accuracy: 0.5673\n",
      "Epoch 52/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0979 - accuracy: 0.5670 - val_loss: 2.0962 - val_accuracy: 0.5686\n",
      "Epoch 53/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 2.0929 - accuracy: 0.5718 - val_loss: 2.0912 - val_accuracy: 0.5704\n",
      "Epoch 54/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.0877 - accuracy: 0.5735 - val_loss: 2.0860 - val_accuracy: 0.5705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0826 - accuracy: 0.5709 - val_loss: 2.0809 - val_accuracy: 0.5722\n",
      "Epoch 56/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0774 - accuracy: 0.5731 - val_loss: 2.0757 - val_accuracy: 0.5731\n",
      "Epoch 57/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.0721 - accuracy: 0.5751 - val_loss: 2.0704 - val_accuracy: 0.5730\n",
      "Epoch 58/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0668 - accuracy: 0.5756 - val_loss: 2.0651 - val_accuracy: 0.5742\n",
      "Epoch 59/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0614 - accuracy: 0.5759 - val_loss: 2.0597 - val_accuracy: 0.5757\n",
      "Epoch 60/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.0560 - accuracy: 0.5804 - val_loss: 2.0543 - val_accuracy: 0.5760\n",
      "Epoch 61/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0505 - accuracy: 0.5793 - val_loss: 2.0488 - val_accuracy: 0.5779\n",
      "Epoch 62/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.0450 - accuracy: 0.5839 - val_loss: 2.0433 - val_accuracy: 0.5785\n",
      "Epoch 63/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.0394 - accuracy: 0.5833 - val_loss: 2.0377 - val_accuracy: 0.5803\n",
      "Epoch 64/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0338 - accuracy: 0.5826 - val_loss: 2.0321 - val_accuracy: 0.5808\n",
      "Epoch 65/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0281 - accuracy: 0.5847 - val_loss: 2.0265 - val_accuracy: 0.5831\n",
      "Epoch 66/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 2.0224 - accuracy: 0.5856 - val_loss: 2.0207 - val_accuracy: 0.5837\n",
      "Epoch 67/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 2.0166 - accuracy: 0.5878 - val_loss: 2.0150 - val_accuracy: 0.5842\n",
      "Epoch 68/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0108 - accuracy: 0.5895 - val_loss: 2.0092 - val_accuracy: 0.5843\n",
      "Epoch 69/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 2.0049 - accuracy: 0.5905 - val_loss: 2.0033 - val_accuracy: 0.5847\n",
      "Epoch 70/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.9990 - accuracy: 0.5910 - val_loss: 1.9974 - val_accuracy: 0.5860\n",
      "Epoch 71/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.9931 - accuracy: 0.5927 - val_loss: 1.9915 - val_accuracy: 0.5868\n",
      "Epoch 72/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.9871 - accuracy: 0.5912 - val_loss: 1.9855 - val_accuracy: 0.5877\n",
      "Epoch 73/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.9811 - accuracy: 0.5933 - val_loss: 1.9795 - val_accuracy: 0.5902\n",
      "Epoch 74/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.9750 - accuracy: 0.5942 - val_loss: 1.9735 - val_accuracy: 0.5915\n",
      "Epoch 75/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.9689 - accuracy: 0.5961 - val_loss: 1.9674 - val_accuracy: 0.5919\n",
      "Epoch 76/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.9628 - accuracy: 0.5960 - val_loss: 1.9612 - val_accuracy: 0.5930\n",
      "Epoch 77/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.9566 - accuracy: 0.5977 - val_loss: 1.9551 - val_accuracy: 0.5939\n",
      "Epoch 78/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.9504 - accuracy: 0.5980 - val_loss: 1.9489 - val_accuracy: 0.5951\n",
      "Epoch 79/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.9442 - accuracy: 0.5997 - val_loss: 1.9427 - val_accuracy: 0.5958\n",
      "Epoch 80/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.9379 - accuracy: 0.6007 - val_loss: 1.9364 - val_accuracy: 0.5962\n",
      "Epoch 81/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.9316 - accuracy: 0.6023 - val_loss: 1.9301 - val_accuracy: 0.5970\n",
      "Epoch 82/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.9253 - accuracy: 0.6020 - val_loss: 1.9238 - val_accuracy: 0.5979\n",
      "Epoch 83/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.9189 - accuracy: 0.6025 - val_loss: 1.9175 - val_accuracy: 0.5991\n",
      "Epoch 84/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.9126 - accuracy: 0.6034 - val_loss: 1.9111 - val_accuracy: 0.6001\n",
      "Epoch 85/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.9062 - accuracy: 0.6047 - val_loss: 1.9048 - val_accuracy: 0.6006\n",
      "Epoch 86/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.8998 - accuracy: 0.6053 - val_loss: 1.8984 - val_accuracy: 0.6011\n",
      "Epoch 87/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.8933 - accuracy: 0.6062 - val_loss: 1.8920 - val_accuracy: 0.6026\n",
      "Epoch 88/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.8869 - accuracy: 0.6069 - val_loss: 1.8855 - val_accuracy: 0.6035\n",
      "Epoch 89/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.8804 - accuracy: 0.6079 - val_loss: 1.8791 - val_accuracy: 0.6047\n",
      "Epoch 90/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.8740 - accuracy: 0.6086 - val_loss: 1.8726 - val_accuracy: 0.6058\n",
      "Epoch 91/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.8675 - accuracy: 0.6099 - val_loss: 1.8662 - val_accuracy: 0.6066\n",
      "Epoch 92/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.8610 - accuracy: 0.6109 - val_loss: 1.8597 - val_accuracy: 0.6072\n",
      "Epoch 93/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.8545 - accuracy: 0.6105 - val_loss: 1.8532 - val_accuracy: 0.6075\n",
      "Epoch 94/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.8480 - accuracy: 0.6118 - val_loss: 1.8468 - val_accuracy: 0.6080\n",
      "Epoch 95/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.8415 - accuracy: 0.6124 - val_loss: 1.8403 - val_accuracy: 0.6084\n",
      "Epoch 96/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.8350 - accuracy: 0.6133 - val_loss: 1.8338 - val_accuracy: 0.6086\n",
      "Epoch 97/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.8285 - accuracy: 0.6133 - val_loss: 1.8273 - val_accuracy: 0.6099\n",
      "Epoch 98/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.8220 - accuracy: 0.6148 - val_loss: 1.8209 - val_accuracy: 0.6105\n",
      "Epoch 99/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.8155 - accuracy: 0.6155 - val_loss: 1.8144 - val_accuracy: 0.6102\n",
      "Epoch 100/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.8090 - accuracy: 0.6157 - val_loss: 1.8080 - val_accuracy: 0.6107\n",
      "Epoch 101/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.8026 - accuracy: 0.6170 - val_loss: 1.8015 - val_accuracy: 0.6110\n",
      "Epoch 102/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.7961 - accuracy: 0.6168 - val_loss: 1.7951 - val_accuracy: 0.6119\n",
      "Epoch 103/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.7897 - accuracy: 0.6177 - val_loss: 1.7887 - val_accuracy: 0.6128\n",
      "Epoch 104/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.7832 - accuracy: 0.6178 - val_loss: 1.7823 - val_accuracy: 0.6136\n",
      "Epoch 105/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.7768 - accuracy: 0.6190 - val_loss: 1.7759 - val_accuracy: 0.6143\n",
      "Epoch 106/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.7704 - accuracy: 0.6186 - val_loss: 1.7695 - val_accuracy: 0.6152\n",
      "Epoch 107/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.7640 - accuracy: 0.6198 - val_loss: 1.7631 - val_accuracy: 0.6160\n",
      "Epoch 108/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.7577 - accuracy: 0.6191 - val_loss: 1.7568 - val_accuracy: 0.6163\n",
      "Epoch 109/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.7513 - accuracy: 0.6204 - val_loss: 1.7505 - val_accuracy: 0.6168\n",
      "Epoch 110/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.7450 - accuracy: 0.6202 - val_loss: 1.7442 - val_accuracy: 0.6177\n",
      "Epoch 111/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.7387 - accuracy: 0.6199 - val_loss: 1.7379 - val_accuracy: 0.6181\n",
      "Epoch 112/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.7324 - accuracy: 0.6211 - val_loss: 1.7317 - val_accuracy: 0.6183\n",
      "Epoch 113/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.7262 - accuracy: 0.6218 - val_loss: 1.7255 - val_accuracy: 0.6184\n",
      "Epoch 114/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.7200 - accuracy: 0.6220 - val_loss: 1.7193 - val_accuracy: 0.6183\n",
      "Epoch 115/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.7138 - accuracy: 0.6222 - val_loss: 1.7131 - val_accuracy: 0.6189\n",
      "Epoch 116/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.7076 - accuracy: 0.6226 - val_loss: 1.7070 - val_accuracy: 0.6192\n",
      "Epoch 117/600\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 1.7015 - accuracy: 0.6228 - val_loss: 1.7009 - val_accuracy: 0.6192\n",
      "Epoch 118/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.6954 - accuracy: 0.6229 - val_loss: 1.6948 - val_accuracy: 0.6194\n",
      "Epoch 119/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.6893 - accuracy: 0.6230 - val_loss: 1.6888 - val_accuracy: 0.6203\n",
      "Epoch 120/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.6833 - accuracy: 0.6234 - val_loss: 1.6828 - val_accuracy: 0.6208\n",
      "Epoch 121/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.6773 - accuracy: 0.6242 - val_loss: 1.6768 - val_accuracy: 0.6206\n",
      "Epoch 122/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.6713 - accuracy: 0.6241 - val_loss: 1.6709 - val_accuracy: 0.6212\n",
      "Epoch 123/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.6653 - accuracy: 0.6243 - val_loss: 1.6650 - val_accuracy: 0.6212\n",
      "Epoch 124/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.6594 - accuracy: 0.6247 - val_loss: 1.6591 - val_accuracy: 0.6210\n",
      "Epoch 125/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.6536 - accuracy: 0.6249 - val_loss: 1.6533 - val_accuracy: 0.6210\n",
      "Epoch 126/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.6477 - accuracy: 0.6252 - val_loss: 1.6475 - val_accuracy: 0.6208\n",
      "Epoch 127/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.6419 - accuracy: 0.6252 - val_loss: 1.6417 - val_accuracy: 0.6212\n",
      "Epoch 128/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.6362 - accuracy: 0.6255 - val_loss: 1.6360 - val_accuracy: 0.6213\n",
      "Epoch 129/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.6305 - accuracy: 0.6258 - val_loss: 1.6303 - val_accuracy: 0.6224\n",
      "Epoch 130/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.6248 - accuracy: 0.6261 - val_loss: 1.6246 - val_accuracy: 0.6234\n",
      "Epoch 131/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.6191 - accuracy: 0.6264 - val_loss: 1.6190 - val_accuracy: 0.6237\n",
      "Epoch 132/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.6135 - accuracy: 0.6271 - val_loss: 1.6134 - val_accuracy: 0.6237\n",
      "Epoch 133/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.6079 - accuracy: 0.6275 - val_loss: 1.6079 - val_accuracy: 0.6237\n",
      "Epoch 134/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.6024 - accuracy: 0.6271 - val_loss: 1.6024 - val_accuracy: 0.6238\n",
      "Epoch 135/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.5969 - accuracy: 0.6272 - val_loss: 1.5969 - val_accuracy: 0.6242\n",
      "Epoch 136/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.5914 - accuracy: 0.6273 - val_loss: 1.5915 - val_accuracy: 0.6242\n",
      "Epoch 137/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.5860 - accuracy: 0.6275 - val_loss: 1.5861 - val_accuracy: 0.6247\n",
      "Epoch 138/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.5806 - accuracy: 0.6277 - val_loss: 1.5807 - val_accuracy: 0.6247\n",
      "Epoch 139/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.5753 - accuracy: 0.6283 - val_loss: 1.5754 - val_accuracy: 0.6248\n",
      "Epoch 140/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.5700 - accuracy: 0.6286 - val_loss: 1.5702 - val_accuracy: 0.6250\n",
      "Epoch 141/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.5647 - accuracy: 0.6284 - val_loss: 1.5649 - val_accuracy: 0.6246\n",
      "Epoch 142/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.5595 - accuracy: 0.6279 - val_loss: 1.5597 - val_accuracy: 0.6242\n",
      "Epoch 143/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.5543 - accuracy: 0.6279 - val_loss: 1.5546 - val_accuracy: 0.6248\n",
      "Epoch 144/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.5491 - accuracy: 0.6284 - val_loss: 1.5494 - val_accuracy: 0.6252\n",
      "Epoch 145/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.5440 - accuracy: 0.6292 - val_loss: 1.5444 - val_accuracy: 0.6248\n",
      "Epoch 146/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.5390 - accuracy: 0.6291 - val_loss: 1.5393 - val_accuracy: 0.6249\n",
      "Epoch 147/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.5339 - accuracy: 0.6293 - val_loss: 1.5343 - val_accuracy: 0.6249\n",
      "Epoch 148/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.5289 - accuracy: 0.6298 - val_loss: 1.5293 - val_accuracy: 0.6248\n",
      "Epoch 149/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.5239 - accuracy: 0.6298 - val_loss: 1.5244 - val_accuracy: 0.6253\n",
      "Epoch 150/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.5190 - accuracy: 0.6302 - val_loss: 1.5195 - val_accuracy: 0.6248\n",
      "Epoch 151/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.5141 - accuracy: 0.6305 - val_loss: 1.5146 - val_accuracy: 0.6248\n",
      "Epoch 152/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.5093 - accuracy: 0.6301 - val_loss: 1.5098 - val_accuracy: 0.6253\n",
      "Epoch 153/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.5045 - accuracy: 0.6306 - val_loss: 1.5050 - val_accuracy: 0.6262\n",
      "Epoch 154/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.4997 - accuracy: 0.6296 - val_loss: 1.5003 - val_accuracy: 0.6267\n",
      "Epoch 155/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.4949 - accuracy: 0.6312 - val_loss: 1.4956 - val_accuracy: 0.6263\n",
      "Epoch 156/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.4902 - accuracy: 0.6315 - val_loss: 1.4909 - val_accuracy: 0.6263\n",
      "Epoch 157/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.4856 - accuracy: 0.6311 - val_loss: 1.4863 - val_accuracy: 0.6267\n",
      "Epoch 158/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.4809 - accuracy: 0.6315 - val_loss: 1.4817 - val_accuracy: 0.6267\n",
      "Epoch 159/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.4763 - accuracy: 0.6316 - val_loss: 1.4771 - val_accuracy: 0.6269\n",
      "Epoch 160/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.4718 - accuracy: 0.6319 - val_loss: 1.4726 - val_accuracy: 0.6271\n",
      "Epoch 161/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.4672 - accuracy: 0.6323 - val_loss: 1.4681 - val_accuracy: 0.6273\n",
      "Epoch 162/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.4628 - accuracy: 0.6318 - val_loss: 1.4636 - val_accuracy: 0.6273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/600\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.4583 - accuracy: 0.6329 - val_loss: 1.4592 - val_accuracy: 0.6277\n",
      "Epoch 164/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.4539 - accuracy: 0.6322 - val_loss: 1.4548 - val_accuracy: 0.6280\n",
      "Epoch 165/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.4495 - accuracy: 0.6332 - val_loss: 1.4504 - val_accuracy: 0.6286\n",
      "Epoch 166/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.4451 - accuracy: 0.6327 - val_loss: 1.4461 - val_accuracy: 0.6286\n",
      "Epoch 167/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.4408 - accuracy: 0.6327 - val_loss: 1.4418 - val_accuracy: 0.6288\n",
      "Epoch 168/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.4365 - accuracy: 0.6332 - val_loss: 1.4376 - val_accuracy: 0.6292\n",
      "Epoch 169/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.4323 - accuracy: 0.6338 - val_loss: 1.4333 - val_accuracy: 0.6292\n",
      "Epoch 170/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.4281 - accuracy: 0.6337 - val_loss: 1.4292 - val_accuracy: 0.6296\n",
      "Epoch 171/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.4239 - accuracy: 0.6339 - val_loss: 1.4250 - val_accuracy: 0.6305\n",
      "Epoch 172/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.4197 - accuracy: 0.6340 - val_loss: 1.4209 - val_accuracy: 0.6304\n",
      "Epoch 173/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.4156 - accuracy: 0.6337 - val_loss: 1.4168 - val_accuracy: 0.6307\n",
      "Epoch 174/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.4115 - accuracy: 0.6348 - val_loss: 1.4127 - val_accuracy: 0.6309\n",
      "Epoch 175/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.4074 - accuracy: 0.6344 - val_loss: 1.4087 - val_accuracy: 0.6310\n",
      "Epoch 176/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.4034 - accuracy: 0.6356 - val_loss: 1.4047 - val_accuracy: 0.6313\n",
      "Epoch 177/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3994 - accuracy: 0.6350 - val_loss: 1.4007 - val_accuracy: 0.6320\n",
      "Epoch 178/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.3955 - accuracy: 0.6352 - val_loss: 1.3968 - val_accuracy: 0.6327\n",
      "Epoch 179/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3915 - accuracy: 0.6360 - val_loss: 1.3929 - val_accuracy: 0.6323\n",
      "Epoch 180/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.3876 - accuracy: 0.6363 - val_loss: 1.3890 - val_accuracy: 0.6320\n",
      "Epoch 181/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.3838 - accuracy: 0.6363 - val_loss: 1.3852 - val_accuracy: 0.6323\n",
      "Epoch 182/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.3799 - accuracy: 0.6367 - val_loss: 1.3814 - val_accuracy: 0.6324\n",
      "Epoch 183/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.3761 - accuracy: 0.6364 - val_loss: 1.3776 - val_accuracy: 0.6326\n",
      "Epoch 184/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.3723 - accuracy: 0.6369 - val_loss: 1.3739 - val_accuracy: 0.6327\n",
      "Epoch 185/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.3686 - accuracy: 0.6371 - val_loss: 1.3702 - val_accuracy: 0.6328\n",
      "Epoch 186/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.3649 - accuracy: 0.6366 - val_loss: 1.3665 - val_accuracy: 0.6331\n",
      "Epoch 187/600\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 1.3612 - accuracy: 0.6375 - val_loss: 1.3628 - val_accuracy: 0.6336\n",
      "Epoch 188/600\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 1.3575 - accuracy: 0.6381 - val_loss: 1.3592 - val_accuracy: 0.6336\n",
      "Epoch 189/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3539 - accuracy: 0.6386 - val_loss: 1.3556 - val_accuracy: 0.6338\n",
      "Epoch 190/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3502 - accuracy: 0.6381 - val_loss: 1.3520 - val_accuracy: 0.6342\n",
      "Epoch 191/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3467 - accuracy: 0.6391 - val_loss: 1.3484 - val_accuracy: 0.6352\n",
      "Epoch 192/600\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.3431 - accuracy: 0.6384 - val_loss: 1.3449 - val_accuracy: 0.6353\n",
      "Epoch 193/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3396 - accuracy: 0.6397 - val_loss: 1.3414 - val_accuracy: 0.6351\n",
      "Epoch 194/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3361 - accuracy: 0.6393 - val_loss: 1.3380 - val_accuracy: 0.6354\n",
      "Epoch 195/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3326 - accuracy: 0.6396 - val_loss: 1.3345 - val_accuracy: 0.6360\n",
      "Epoch 196/600\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 1.3292 - accuracy: 0.6406 - val_loss: 1.3311 - val_accuracy: 0.6367\n",
      "Epoch 197/600\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.3258 - accuracy: 0.6407 - val_loss: 1.3277 - val_accuracy: 0.6367\n",
      "Epoch 198/600\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.3224 - accuracy: 0.6410 - val_loss: 1.3244 - val_accuracy: 0.6366\n",
      "Epoch 199/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3190 - accuracy: 0.6415 - val_loss: 1.3210 - val_accuracy: 0.6373\n",
      "Epoch 200/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3157 - accuracy: 0.6421 - val_loss: 1.3177 - val_accuracy: 0.6378\n",
      "Epoch 201/600\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.3124 - accuracy: 0.6417 - val_loss: 1.3144 - val_accuracy: 0.6382\n",
      "Epoch 202/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3091 - accuracy: 0.6426 - val_loss: 1.3112 - val_accuracy: 0.6383\n",
      "Epoch 203/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3058 - accuracy: 0.6426 - val_loss: 1.3080 - val_accuracy: 0.6388\n",
      "Epoch 204/600\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.3026 - accuracy: 0.6430 - val_loss: 1.3047 - val_accuracy: 0.6398\n",
      "Epoch 205/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.2993 - accuracy: 0.6442 - val_loss: 1.3016 - val_accuracy: 0.6400\n",
      "Epoch 206/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.2961 - accuracy: 0.6443 - val_loss: 1.2984 - val_accuracy: 0.6404\n",
      "Epoch 207/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.2930 - accuracy: 0.6441 - val_loss: 1.2953 - val_accuracy: 0.6406\n",
      "Epoch 208/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.2898 - accuracy: 0.6453 - val_loss: 1.2922 - val_accuracy: 0.6405\n",
      "Epoch 209/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2867 - accuracy: 0.6450 - val_loss: 1.2891 - val_accuracy: 0.6413\n",
      "Epoch 210/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.2836 - accuracy: 0.6460 - val_loss: 1.2860 - val_accuracy: 0.6411\n",
      "Epoch 211/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.2805 - accuracy: 0.6460 - val_loss: 1.2830 - val_accuracy: 0.6413\n",
      "Epoch 212/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.2775 - accuracy: 0.6462 - val_loss: 1.2799 - val_accuracy: 0.6420- loss: 1.2776 - accuracy: 0.64\n",
      "Epoch 213/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.2745 - accuracy: 0.6470 - val_loss: 1.2770 - val_accuracy: 0.6425\n",
      "Epoch 214/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2715 - accuracy: 0.6470 - val_loss: 1.2740 - val_accuracy: 0.6427\n",
      "Epoch 215/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2685 - accuracy: 0.6475 - val_loss: 1.2710 - val_accuracy: 0.6428\n",
      "Epoch 216/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2655 - accuracy: 0.6482 - val_loss: 1.2681 - val_accuracy: 0.6435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.2626 - accuracy: 0.6481 - val_loss: 1.2652 - val_accuracy: 0.6439\n",
      "Epoch 218/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2596 - accuracy: 0.6486 - val_loss: 1.2623 - val_accuracy: 0.6443\n",
      "Epoch 219/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2567 - accuracy: 0.6494 - val_loss: 1.2594 - val_accuracy: 0.6447\n",
      "Epoch 220/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2539 - accuracy: 0.6502 - val_loss: 1.2566 - val_accuracy: 0.6447\n",
      "Epoch 221/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.2510 - accuracy: 0.6505 - val_loss: 1.2538 - val_accuracy: 0.6450\n",
      "Epoch 222/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2482 - accuracy: 0.6505 - val_loss: 1.2509 - val_accuracy: 0.6449\n",
      "Epoch 223/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.2454 - accuracy: 0.6513 - val_loss: 1.2482 - val_accuracy: 0.6453\n",
      "Epoch 224/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.2426 - accuracy: 0.6511 - val_loss: 1.2454 - val_accuracy: 0.6460\n",
      "Epoch 225/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2398 - accuracy: 0.6516 - val_loss: 1.2427 - val_accuracy: 0.6465\n",
      "Epoch 226/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2370 - accuracy: 0.6520 - val_loss: 1.2399 - val_accuracy: 0.6470\n",
      "Epoch 227/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2343 - accuracy: 0.6526 - val_loss: 1.2372 - val_accuracy: 0.6471\n",
      "Epoch 228/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.2316 - accuracy: 0.6527 - val_loss: 1.2345 - val_accuracy: 0.6475\n",
      "Epoch 229/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2289 - accuracy: 0.6531 - val_loss: 1.2319 - val_accuracy: 0.6478\n",
      "Epoch 230/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.2262 - accuracy: 0.6537 - val_loss: 1.2292 - val_accuracy: 0.6476\n",
      "Epoch 231/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2235 - accuracy: 0.6540 - val_loss: 1.2266 - val_accuracy: 0.6477\n",
      "Epoch 232/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.2209 - accuracy: 0.6543 - val_loss: 1.2240 - val_accuracy: 0.6486\n",
      "Epoch 233/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2182 - accuracy: 0.6549 - val_loss: 1.2214 - val_accuracy: 0.6490\n",
      "Epoch 234/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.2156 - accuracy: 0.6551 - val_loss: 1.2188 - val_accuracy: 0.6497\n",
      "Epoch 235/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2130 - accuracy: 0.6553 - val_loss: 1.2162 - val_accuracy: 0.6498\n",
      "Epoch 236/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2105 - accuracy: 0.6558 - val_loss: 1.2137 - val_accuracy: 0.6503\n",
      "Epoch 237/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2079 - accuracy: 0.6557 - val_loss: 1.2112 - val_accuracy: 0.6506\n",
      "Epoch 238/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2054 - accuracy: 0.6560 - val_loss: 1.2087 - val_accuracy: 0.6506\n",
      "Epoch 239/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2028 - accuracy: 0.6566 - val_loss: 1.2062 - val_accuracy: 0.6510\n",
      "Epoch 240/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.2003 - accuracy: 0.6567 - val_loss: 1.2037 - val_accuracy: 0.6516\n",
      "Epoch 241/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1978 - accuracy: 0.6577 - val_loss: 1.2012 - val_accuracy: 0.6522\n",
      "Epoch 242/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.1954 - accuracy: 0.6577 - val_loss: 1.1988 - val_accuracy: 0.6525\n",
      "Epoch 243/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1929 - accuracy: 0.6580 - val_loss: 1.1964 - val_accuracy: 0.6524\n",
      "Epoch 244/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1905 - accuracy: 0.6583 - val_loss: 1.1940 - val_accuracy: 0.6528\n",
      "Epoch 245/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1880 - accuracy: 0.6588 - val_loss: 1.1916 - val_accuracy: 0.6535\n",
      "Epoch 246/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1856 - accuracy: 0.6589 - val_loss: 1.1892 - val_accuracy: 0.6542\n",
      "Epoch 247/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.1832 - accuracy: 0.6599 - val_loss: 1.1868 - val_accuracy: 0.6546\n",
      "Epoch 248/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.1809 - accuracy: 0.6601 - val_loss: 1.1845 - val_accuracy: 0.6547\n",
      "Epoch 249/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.1785 - accuracy: 0.6608 - val_loss: 1.1821 - val_accuracy: 0.6548\n",
      "Epoch 250/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.1761 - accuracy: 0.6609 - val_loss: 1.1798 - val_accuracy: 0.6555\n",
      "Epoch 251/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.1738 - accuracy: 0.6610 - val_loss: 1.1775 - val_accuracy: 0.6567\n",
      "Epoch 252/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.1715 - accuracy: 0.6617 - val_loss: 1.1752 - val_accuracy: 0.6571\n",
      "Epoch 253/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1692 - accuracy: 0.6623 - val_loss: 1.1729 - val_accuracy: 0.6571\n",
      "Epoch 254/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.1669 - accuracy: 0.6627 - val_loss: 1.1707 - val_accuracy: 0.6571\n",
      "Epoch 255/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1646 - accuracy: 0.6630 - val_loss: 1.1684 - val_accuracy: 0.6580\n",
      "Epoch 256/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1623 - accuracy: 0.6633 - val_loss: 1.1662 - val_accuracy: 0.6587\n",
      "Epoch 257/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1601 - accuracy: 0.6641 - val_loss: 1.1640 - val_accuracy: 0.6593\n",
      "Epoch 258/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1579 - accuracy: 0.6643 - val_loss: 1.1618 - val_accuracy: 0.6596\n",
      "Epoch 259/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1556 - accuracy: 0.6648 - val_loss: 1.1596 - val_accuracy: 0.6602\n",
      "Epoch 260/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.1534 - accuracy: 0.6656 - val_loss: 1.1574 - val_accuracy: 0.6604\n",
      "Epoch 261/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1512 - accuracy: 0.6660 - val_loss: 1.1552 - val_accuracy: 0.6607\n",
      "Epoch 262/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1490 - accuracy: 0.6662 - val_loss: 1.1531 - val_accuracy: 0.6613\n",
      "Epoch 263/600\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 1.1469 - accuracy: 0.6665 - val_loss: 1.1510 - val_accuracy: 0.6617\n",
      "Epoch 264/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.1447 - accuracy: 0.6675 - val_loss: 1.1488 - val_accuracy: 0.6622\n",
      "Epoch 265/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.1426 - accuracy: 0.6676 - val_loss: 1.1467 - val_accuracy: 0.6627\n",
      "Epoch 266/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.1404 - accuracy: 0.6679 - val_loss: 1.1446 - val_accuracy: 0.6633\n",
      "Epoch 267/600\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.1383 - accuracy: 0.6687 - val_loss: 1.1425 - val_accuracy: 0.6633\n",
      "Epoch 268/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.1362 - accuracy: 0.6688 - val_loss: 1.1404 - val_accuracy: 0.6637\n",
      "Epoch 269/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.1341 - accuracy: 0.6694 - val_loss: 1.1384 - val_accuracy: 0.6643\n",
      "Epoch 270/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.1320 - accuracy: 0.6700 - val_loss: 1.1363 - val_accuracy: 0.6648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.1300 - accuracy: 0.6699 - val_loss: 1.1343 - val_accuracy: 0.6652\n",
      "Epoch 272/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.1279 - accuracy: 0.6704 - val_loss: 1.1323 - val_accuracy: 0.6658\n",
      "Epoch 273/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.1259 - accuracy: 0.6708 - val_loss: 1.1302 - val_accuracy: 0.6658\n",
      "Epoch 274/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.1238 - accuracy: 0.6712 - val_loss: 1.1282 - val_accuracy: 0.6662\n",
      "Epoch 275/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.1218 - accuracy: 0.6713 - val_loss: 1.1262 - val_accuracy: 0.6665\n",
      "Epoch 276/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1198 - accuracy: 0.6718 - val_loss: 1.1243 - val_accuracy: 0.6668\n",
      "Epoch 277/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.1178 - accuracy: 0.6721 - val_loss: 1.1223 - val_accuracy: 0.6672\n",
      "Epoch 278/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.1158 - accuracy: 0.6722 - val_loss: 1.1203 - val_accuracy: 0.6676\n",
      "Epoch 279/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.1138 - accuracy: 0.6730 - val_loss: 1.1184 - val_accuracy: 0.6680\n",
      "Epoch 280/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.1118 - accuracy: 0.6730 - val_loss: 1.1164 - val_accuracy: 0.6684\n",
      "Epoch 281/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.1099 - accuracy: 0.6734 - val_loss: 1.1145 - val_accuracy: 0.6685\n",
      "Epoch 282/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.1079 - accuracy: 0.6738 - val_loss: 1.1126 - val_accuracy: 0.6688\n",
      "Epoch 283/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1060 - accuracy: 0.6745 - val_loss: 1.1107 - val_accuracy: 0.6693\n",
      "Epoch 284/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1041 - accuracy: 0.6746 - val_loss: 1.1088 - val_accuracy: 0.6699\n",
      "Epoch 285/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1021 - accuracy: 0.6750 - val_loss: 1.1069 - val_accuracy: 0.6704\n",
      "Epoch 286/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.1002 - accuracy: 0.6750 - val_loss: 1.1050 - val_accuracy: 0.6703\n",
      "Epoch 287/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0983 - accuracy: 0.6754 - val_loss: 1.1031 - val_accuracy: 0.6709\n",
      "Epoch 288/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0964 - accuracy: 0.6760 - val_loss: 1.1013 - val_accuracy: 0.6714\n",
      "Epoch 289/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0946 - accuracy: 0.6762 - val_loss: 1.0994 - val_accuracy: 0.6718\n",
      "Epoch 290/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0927 - accuracy: 0.6767 - val_loss: 1.0976 - val_accuracy: 0.6722\n",
      "Epoch 291/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0908 - accuracy: 0.6769 - val_loss: 1.0958 - val_accuracy: 0.6723\n",
      "Epoch 292/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0890 - accuracy: 0.6772 - val_loss: 1.0939 - val_accuracy: 0.6727\n",
      "Epoch 293/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0872 - accuracy: 0.6774 - val_loss: 1.0921 - val_accuracy: 0.6732\n",
      "Epoch 294/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0853 - accuracy: 0.6777 - val_loss: 1.0903 - val_accuracy: 0.6737\n",
      "Epoch 295/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0835 - accuracy: 0.6786 - val_loss: 1.0885 - val_accuracy: 0.6740\n",
      "Epoch 296/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0817 - accuracy: 0.6789 - val_loss: 1.0868 - val_accuracy: 0.6743\n",
      "Epoch 297/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.0799 - accuracy: 0.6791 - val_loss: 1.0850 - val_accuracy: 0.6744\n",
      "Epoch 298/600\n",
      "60000/60000 [==============================] - 1s 21us/sample - loss: 1.0781 - accuracy: 0.6792 - val_loss: 1.0832 - val_accuracy: 0.6749\n",
      "Epoch 299/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.0763 - accuracy: 0.6802 - val_loss: 1.0815 - val_accuracy: 0.6751\n",
      "Epoch 300/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.0745 - accuracy: 0.6799 - val_loss: 1.0797 - val_accuracy: 0.6752\n",
      "Epoch 301/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.0728 - accuracy: 0.6805 - val_loss: 1.0780 - val_accuracy: 0.6752\n",
      "Epoch 302/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0710 - accuracy: 0.6810 - val_loss: 1.0763 - val_accuracy: 0.6759\n",
      "Epoch 303/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0693 - accuracy: 0.6810 - val_loss: 1.0745 - val_accuracy: 0.6763\n",
      "Epoch 304/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0675 - accuracy: 0.6815 - val_loss: 1.0728 - val_accuracy: 0.6768\n",
      "Epoch 305/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.0658 - accuracy: 0.6819 - val_loss: 1.0711 - val_accuracy: 0.6772\n",
      "Epoch 306/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0641 - accuracy: 0.6823 - val_loss: 1.0694 - val_accuracy: 0.6777\n",
      "Epoch 307/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0624 - accuracy: 0.6825 - val_loss: 1.0677 - val_accuracy: 0.6777\n",
      "Epoch 308/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0607 - accuracy: 0.6830 - val_loss: 1.0661 - val_accuracy: 0.6778\n",
      "Epoch 309/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0590 - accuracy: 0.6832 - val_loss: 1.0644 - val_accuracy: 0.6783\n",
      "Epoch 310/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0573 - accuracy: 0.6834 - val_loss: 1.0627 - val_accuracy: 0.6787\n",
      "Epoch 311/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0556 - accuracy: 0.6835 - val_loss: 1.0611 - val_accuracy: 0.6790\n",
      "Epoch 312/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0539 - accuracy: 0.6839 - val_loss: 1.0594 - val_accuracy: 0.6793\n",
      "Epoch 313/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0523 - accuracy: 0.6843 - val_loss: 1.0578 - val_accuracy: 0.6796\n",
      "Epoch 314/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.0506 - accuracy: 0.6847 - val_loss: 1.0562 - val_accuracy: 0.6797\n",
      "Epoch 315/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.0489 - accuracy: 0.6850 - val_loss: 1.0545 - val_accuracy: 0.6798\n",
      "Epoch 316/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.0473 - accuracy: 0.6851 - val_loss: 1.0529 - val_accuracy: 0.6798\n",
      "Epoch 317/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0457 - accuracy: 0.6857 - val_loss: 1.0513 - val_accuracy: 0.6805\n",
      "Epoch 318/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.0440 - accuracy: 0.6859 - val_loss: 1.0497 - val_accuracy: 0.6812\n",
      "Epoch 319/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0424 - accuracy: 0.6862 - val_loss: 1.0481 - val_accuracy: 0.6812\n",
      "Epoch 320/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0408 - accuracy: 0.6864 - val_loss: 1.0465 - val_accuracy: 0.6812\n",
      "Epoch 321/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0392 - accuracy: 0.6870 - val_loss: 1.0450 - val_accuracy: 0.6817\n",
      "Epoch 322/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.0376 - accuracy: 0.6871 - val_loss: 1.0434 - val_accuracy: 0.6818\n",
      "Epoch 323/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0360 - accuracy: 0.6873 - val_loss: 1.0418 - val_accuracy: 0.6822\n",
      "Epoch 324/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 1.0344 - accuracy: 0.6875 - val_loss: 1.0403 - val_accuracy: 0.6823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0329 - accuracy: 0.6878 - val_loss: 1.0387 - val_accuracy: 0.6827\n",
      "Epoch 326/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0313 - accuracy: 0.6880 - val_loss: 1.0372 - val_accuracy: 0.6828\n",
      "Epoch 327/600\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.0297 - accuracy: 0.6885 - val_loss: 1.0356 - val_accuracy: 0.6832\n",
      "Epoch 328/600\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 1.0282 - accuracy: 0.6886 - val_loss: 1.0341 - val_accuracy: 0.6836\n",
      "Epoch 329/600\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 1.0266 - accuracy: 0.6893 - val_loss: 1.0326 - val_accuracy: 0.6840\n",
      "Epoch 330/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 1.0251 - accuracy: 0.6893 - val_loss: 1.0311 - val_accuracy: 0.6842\n",
      "Epoch 331/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0235 - accuracy: 0.6898 - val_loss: 1.0296 - val_accuracy: 0.6844\n",
      "Epoch 332/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0220 - accuracy: 0.6901 - val_loss: 1.0281 - val_accuracy: 0.6847\n",
      "Epoch 333/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0205 - accuracy: 0.6902 - val_loss: 1.0266 - val_accuracy: 0.6848\n",
      "Epoch 334/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0190 - accuracy: 0.6908 - val_loss: 1.0251 - val_accuracy: 0.6852\n",
      "Epoch 335/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0175 - accuracy: 0.6908 - val_loss: 1.0236 - val_accuracy: 0.6853\n",
      "Epoch 336/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0160 - accuracy: 0.6909 - val_loss: 1.0221 - val_accuracy: 0.6854\n",
      "Epoch 337/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0145 - accuracy: 0.6912 - val_loss: 1.0206 - val_accuracy: 0.6858\n",
      "Epoch 338/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0130 - accuracy: 0.6916 - val_loss: 1.0192 - val_accuracy: 0.6862\n",
      "Epoch 339/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0115 - accuracy: 0.6916 - val_loss: 1.0177 - val_accuracy: 0.6864\n",
      "Epoch 340/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 1.0100 - accuracy: 0.6921 - val_loss: 1.0163 - val_accuracy: 0.6862\n",
      "Epoch 341/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0086 - accuracy: 0.6924 - val_loss: 1.0148 - val_accuracy: 0.6867\n",
      "Epoch 342/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0071 - accuracy: 0.6924 - val_loss: 1.0134 - val_accuracy: 0.6872\n",
      "Epoch 343/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0056 - accuracy: 0.6930 - val_loss: 1.0120 - val_accuracy: 0.6874\n",
      "Epoch 344/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0042 - accuracy: 0.6932 - val_loss: 1.0105 - val_accuracy: 0.6875\n",
      "Epoch 345/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0027 - accuracy: 0.6936 - val_loss: 1.0091 - val_accuracy: 0.6876\n",
      "Epoch 346/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 1.0013 - accuracy: 0.6937 - val_loss: 1.0077 - val_accuracy: 0.6877\n",
      "Epoch 347/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.9999 - accuracy: 0.6940 - val_loss: 1.0063 - val_accuracy: 0.6881\n",
      "Epoch 348/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.9985 - accuracy: 0.6942 - val_loss: 1.0049 - val_accuracy: 0.6883\n",
      "Epoch 349/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.9970 - accuracy: 0.6946 - val_loss: 1.0035 - val_accuracy: 0.6885\n",
      "Epoch 350/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.9956 - accuracy: 0.6948 - val_loss: 1.0021 - val_accuracy: 0.6888\n",
      "Epoch 351/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.9942 - accuracy: 0.6951 - val_loss: 1.0007 - val_accuracy: 0.6892\n",
      "Epoch 352/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.9928 - accuracy: 0.6956 - val_loss: 0.9993 - val_accuracy: 0.6893\n",
      "Epoch 353/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9914 - accuracy: 0.6955 - val_loss: 0.9980 - val_accuracy: 0.6896\n",
      "Epoch 354/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9900 - accuracy: 0.6962 - val_loss: 0.9966 - val_accuracy: 0.6897\n",
      "Epoch 355/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.9886 - accuracy: 0.6960 - val_loss: 0.9952 - val_accuracy: 0.6898\n",
      "Epoch 356/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9872 - accuracy: 0.6964 - val_loss: 0.9939 - val_accuracy: 0.6898\n",
      "Epoch 357/600\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.9859 - accuracy: 0.6967 - val_loss: 0.9925 - val_accuracy: 0.6902\n",
      "Epoch 358/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.9845 - accuracy: 0.6971 - val_loss: 0.9912 - val_accuracy: 0.6903\n",
      "Epoch 359/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9831 - accuracy: 0.6973 - val_loss: 0.9898 - val_accuracy: 0.6909\n",
      "Epoch 360/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.9818 - accuracy: 0.6975 - val_loss: 0.9885 - val_accuracy: 0.6909\n",
      "Epoch 361/600\n",
      "60000/60000 [==============================] - 1s 17us/sample - loss: 0.9804 - accuracy: 0.6975 - val_loss: 0.9872 - val_accuracy: 0.6916\n",
      "Epoch 362/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9791 - accuracy: 0.6981 - val_loss: 0.9858 - val_accuracy: 0.6917\n",
      "Epoch 363/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9777 - accuracy: 0.6982 - val_loss: 0.9845 - val_accuracy: 0.6921\n",
      "Epoch 364/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9764 - accuracy: 0.6984 - val_loss: 0.9832 - val_accuracy: 0.6922\n",
      "Epoch 365/600\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.9751 - accuracy: 0.6985 - val_loss: 0.9819 - val_accuracy: 0.6918\n",
      "Epoch 366/600\n",
      "60000/60000 [==============================] - 1s 19us/sample - loss: 0.9737 - accuracy: 0.6985 - val_loss: 0.9806 - val_accuracy: 0.6924\n",
      "Epoch 367/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9724 - accuracy: 0.6988 - val_loss: 0.9793 - val_accuracy: 0.6927\n",
      "Epoch 368/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9711 - accuracy: 0.6992 - val_loss: 0.9780 - val_accuracy: 0.6928\n",
      "Epoch 369/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9698 - accuracy: 0.6995 - val_loss: 0.9767 - val_accuracy: 0.6931\n",
      "Epoch 370/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9685 - accuracy: 0.6995 - val_loss: 0.9754 - val_accuracy: 0.6934\n",
      "Epoch 371/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9672 - accuracy: 0.6999 - val_loss: 0.9742 - val_accuracy: 0.6938\n",
      "Epoch 372/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9659 - accuracy: 0.7005 - val_loss: 0.9729 - val_accuracy: 0.6938\n",
      "Epoch 373/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9646 - accuracy: 0.7007 - val_loss: 0.9716 - val_accuracy: 0.6942\n",
      "Epoch 374/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9633 - accuracy: 0.7008 - val_loss: 0.9704 - val_accuracy: 0.6942\n",
      "Epoch 375/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9620 - accuracy: 0.7011 - val_loss: 0.9691 - val_accuracy: 0.6947\n",
      "Epoch 376/600\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.9608 - accuracy: 0.7014 - val_loss: 0.9678 - val_accuracy: 0.6954\n",
      "Epoch 377/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9595 - accuracy: 0.7016 - val_loss: 0.9666 - val_accuracy: 0.6959\n",
      "Epoch 378/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9582 - accuracy: 0.7017 - val_loss: 0.9654 - val_accuracy: 0.6962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9570 - accuracy: 0.7022 - val_loss: 0.9641 - val_accuracy: 0.6963\n",
      "Epoch 380/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9557 - accuracy: 0.7025 - val_loss: 0.9629 - val_accuracy: 0.6966\n",
      "Epoch 381/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9545 - accuracy: 0.7025 - val_loss: 0.9617 - val_accuracy: 0.6968\n",
      "Epoch 382/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9532 - accuracy: 0.7028 - val_loss: 0.9604 - val_accuracy: 0.6970\n",
      "Epoch 383/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9520 - accuracy: 0.7028 - val_loss: 0.9592 - val_accuracy: 0.6972\n",
      "Epoch 384/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9507 - accuracy: 0.7031 - val_loss: 0.9580 - val_accuracy: 0.6969\n",
      "Epoch 385/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9495 - accuracy: 0.7032 - val_loss: 0.9568 - val_accuracy: 0.6971\n",
      "Epoch 386/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9483 - accuracy: 0.7036 - val_loss: 0.9556 - val_accuracy: 0.6973\n",
      "Epoch 387/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9471 - accuracy: 0.7035 - val_loss: 0.9544 - val_accuracy: 0.6973\n",
      "Epoch 388/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9458 - accuracy: 0.7037 - val_loss: 0.9532 - val_accuracy: 0.6978\n",
      "Epoch 389/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9446 - accuracy: 0.7042 - val_loss: 0.9520 - val_accuracy: 0.6980\n",
      "Epoch 390/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9434 - accuracy: 0.7042 - val_loss: 0.9508 - val_accuracy: 0.6982\n",
      "Epoch 391/600\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.9422 - accuracy: 0.7046 - val_loss: 0.9496 - val_accuracy: 0.6982\n",
      "Epoch 392/600\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9410 - accuracy: 0.7050 - val_loss: 0.9484 - val_accuracy: 0.6982\n",
      "Epoch 393/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9398 - accuracy: 0.7049 - val_loss: 0.9473 - val_accuracy: 0.6988\n",
      "Epoch 394/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9386 - accuracy: 0.7054 - val_loss: 0.9461 - val_accuracy: 0.6991\n",
      "Epoch 395/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9374 - accuracy: 0.7056 - val_loss: 0.9449 - val_accuracy: 0.6992\n",
      "Epoch 396/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9363 - accuracy: 0.7054 - val_loss: 0.9438 - val_accuracy: 0.6997\n",
      "Epoch 397/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9351 - accuracy: 0.7059 - val_loss: 0.9426 - val_accuracy: 0.6998\n",
      "Epoch 398/600\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9339 - accuracy: 0.7061 - val_loss: 0.9415 - val_accuracy: 0.7002\n",
      "Epoch 399/600\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9327 - accuracy: 0.7065 - val_loss: 0.9403 - val_accuracy: 0.7003\n",
      "Epoch 400/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9316 - accuracy: 0.7067 - val_loss: 0.9392 - val_accuracy: 0.7008\n",
      "Epoch 401/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9304 - accuracy: 0.7067 - val_loss: 0.9380 - val_accuracy: 0.7008\n",
      "Epoch 402/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9293 - accuracy: 0.7069 - val_loss: 0.9369 - val_accuracy: 0.7011\n",
      "Epoch 403/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9281 - accuracy: 0.7070 - val_loss: 0.9358 - val_accuracy: 0.7013\n",
      "Epoch 404/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9270 - accuracy: 0.7075 - val_loss: 0.9346 - val_accuracy: 0.7011\n",
      "Epoch 405/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9258 - accuracy: 0.7076 - val_loss: 0.9335 - val_accuracy: 0.7016\n",
      "Epoch 406/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9247 - accuracy: 0.7078 - val_loss: 0.9324 - val_accuracy: 0.7020\n",
      "Epoch 407/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9235 - accuracy: 0.7078 - val_loss: 0.9313 - val_accuracy: 0.7023\n",
      "Epoch 408/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9224 - accuracy: 0.7083 - val_loss: 0.9302 - val_accuracy: 0.7025\n",
      "Epoch 409/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9213 - accuracy: 0.7082 - val_loss: 0.9291 - val_accuracy: 0.7023\n",
      "Epoch 410/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9202 - accuracy: 0.7089 - val_loss: 0.9280 - val_accuracy: 0.7025\n",
      "Epoch 411/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9191 - accuracy: 0.7086 - val_loss: 0.9269 - val_accuracy: 0.7028\n",
      "Epoch 412/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9179 - accuracy: 0.7090 - val_loss: 0.9258 - val_accuracy: 0.7031\n",
      "Epoch 413/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9168 - accuracy: 0.7093 - val_loss: 0.9247 - val_accuracy: 0.7032\n",
      "Epoch 414/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9157 - accuracy: 0.7094 - val_loss: 0.9236 - val_accuracy: 0.7032\n",
      "Epoch 415/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9146 - accuracy: 0.7095 - val_loss: 0.9225 - val_accuracy: 0.7036\n",
      "Epoch 416/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9135 - accuracy: 0.7098 - val_loss: 0.9214 - val_accuracy: 0.7041\n",
      "Epoch 417/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9124 - accuracy: 0.7100 - val_loss: 0.9204 - val_accuracy: 0.7043\n",
      "Epoch 418/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9113 - accuracy: 0.7102 - val_loss: 0.9193 - val_accuracy: 0.7047\n",
      "Epoch 419/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9103 - accuracy: 0.7101 - val_loss: 0.9182 - val_accuracy: 0.7048\n",
      "Epoch 420/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9092 - accuracy: 0.7105 - val_loss: 0.9172 - val_accuracy: 0.7048\n",
      "Epoch 421/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9081 - accuracy: 0.7107 - val_loss: 0.9161 - val_accuracy: 0.7053\n",
      "Epoch 422/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9070 - accuracy: 0.7110 - val_loss: 0.9151 - val_accuracy: 0.7056\n",
      "Epoch 423/600\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9060 - accuracy: 0.7112 - val_loss: 0.9140 - val_accuracy: 0.7059\n",
      "Epoch 424/600\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.9049 - accuracy: 0.7114 - val_loss: 0.9130 - val_accuracy: 0.7063\n",
      "Epoch 425/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9038 - accuracy: 0.7119 - val_loss: 0.9119 - val_accuracy: 0.7067\n",
      "Epoch 426/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9028 - accuracy: 0.7121 - val_loss: 0.9109 - val_accuracy: 0.7070\n",
      "Epoch 427/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9017 - accuracy: 0.7120 - val_loss: 0.9099 - val_accuracy: 0.7069\n",
      "Epoch 428/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.9007 - accuracy: 0.7120 - val_loss: 0.9088 - val_accuracy: 0.7070\n",
      "Epoch 429/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8996 - accuracy: 0.7125 - val_loss: 0.9078 - val_accuracy: 0.7072\n",
      "Epoch 430/600\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.8986 - accuracy: 0.7127 - val_loss: 0.9068 - val_accuracy: 0.7072\n",
      "Epoch 431/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8975 - accuracy: 0.7128 - val_loss: 0.9058 - val_accuracy: 0.7073\n",
      "Epoch 432/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8965 - accuracy: 0.7134 - val_loss: 0.9047 - val_accuracy: 0.7075\n",
      "Epoch 433/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8955 - accuracy: 0.7132 - val_loss: 0.9037 - val_accuracy: 0.7076\n",
      "Epoch 434/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8945 - accuracy: 0.7134 - val_loss: 0.9027 - val_accuracy: 0.7077\n",
      "Epoch 435/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8934 - accuracy: 0.7137 - val_loss: 0.9017 - val_accuracy: 0.7076\n",
      "Epoch 436/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8924 - accuracy: 0.7138 - val_loss: 0.9007 - val_accuracy: 0.7077\n",
      "Epoch 437/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8914 - accuracy: 0.7142 - val_loss: 0.8997 - val_accuracy: 0.7081\n",
      "Epoch 438/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8904 - accuracy: 0.7143 - val_loss: 0.8987 - val_accuracy: 0.7083\n",
      "Epoch 439/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8894 - accuracy: 0.7146 - val_loss: 0.8977 - val_accuracy: 0.7087\n",
      "Epoch 440/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8884 - accuracy: 0.7149 - val_loss: 0.8967 - val_accuracy: 0.7088\n",
      "Epoch 441/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8874 - accuracy: 0.7151 - val_loss: 0.8958 - val_accuracy: 0.7088\n",
      "Epoch 442/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8864 - accuracy: 0.7151 - val_loss: 0.8948 - val_accuracy: 0.7091\n",
      "Epoch 443/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8854 - accuracy: 0.7153 - val_loss: 0.8938 - val_accuracy: 0.7095\n",
      "Epoch 444/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8844 - accuracy: 0.7154 - val_loss: 0.8928 - val_accuracy: 0.7093\n",
      "Epoch 445/600\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.8834 - accuracy: 0.7156 - val_loss: 0.8919 - val_accuracy: 0.7096\n",
      "Epoch 446/600\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.8824 - accuracy: 0.7162 - val_loss: 0.8909 - val_accuracy: 0.7098\n",
      "Epoch 447/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8814 - accuracy: 0.7160 - val_loss: 0.8899 - val_accuracy: 0.7099\n",
      "Epoch 448/600\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.8805 - accuracy: 0.7164 - val_loss: 0.8890 - val_accuracy: 0.7102\n",
      "Epoch 449/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8795 - accuracy: 0.7165 - val_loss: 0.8880 - val_accuracy: 0.7104\n",
      "Epoch 450/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8785 - accuracy: 0.7163 - val_loss: 0.8871 - val_accuracy: 0.7107\n",
      "Epoch 451/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8775 - accuracy: 0.7170 - val_loss: 0.8861 - val_accuracy: 0.7107\n",
      "Epoch 452/600\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.8766 - accuracy: 0.7173 - val_loss: 0.8852 - val_accuracy: 0.7113\n",
      "Epoch 453/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8756 - accuracy: 0.7175 - val_loss: 0.8842 - val_accuracy: 0.7112\n",
      "Epoch 454/600\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.8747 - accuracy: 0.7174 - val_loss: 0.8833 - val_accuracy: 0.7114\n",
      "Epoch 455/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8737 - accuracy: 0.7177 - val_loss: 0.8824 - val_accuracy: 0.7115\n",
      "Epoch 456/600\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.8728 - accuracy: 0.7177 - val_loss: 0.8814 - val_accuracy: 0.7113\n",
      "Epoch 457/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8718 - accuracy: 0.7179 - val_loss: 0.8805 - val_accuracy: 0.7113\n",
      "Epoch 458/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8709 - accuracy: 0.7180 - val_loss: 0.8796 - val_accuracy: 0.7116\n",
      "Epoch 459/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8699 - accuracy: 0.7182 - val_loss: 0.8786 - val_accuracy: 0.7118\n",
      "Epoch 460/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8690 - accuracy: 0.7185 - val_loss: 0.8777 - val_accuracy: 0.7118\n",
      "Epoch 461/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8681 - accuracy: 0.7191 - val_loss: 0.8768 - val_accuracy: 0.7117\n",
      "Epoch 462/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8672 - accuracy: 0.7187 - val_loss: 0.8759 - val_accuracy: 0.7119\n",
      "Epoch 463/600\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.8662 - accuracy: 0.7191 - val_loss: 0.8750 - val_accuracy: 0.7119\n",
      "Epoch 464/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8653 - accuracy: 0.7191 - val_loss: 0.8741 - val_accuracy: 0.7118\n",
      "Epoch 465/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8644 - accuracy: 0.7193 - val_loss: 0.8732 - val_accuracy: 0.7119\n",
      "Epoch 466/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8635 - accuracy: 0.7195 - val_loss: 0.8723 - val_accuracy: 0.7117\n",
      "Epoch 467/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8626 - accuracy: 0.7199 - val_loss: 0.8714 - val_accuracy: 0.7116\n",
      "Epoch 468/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8617 - accuracy: 0.7200 - val_loss: 0.8705 - val_accuracy: 0.7121\n",
      "Epoch 469/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8607 - accuracy: 0.7197 - val_loss: 0.8696 - val_accuracy: 0.7123\n",
      "Epoch 470/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8598 - accuracy: 0.7201 - val_loss: 0.8687 - val_accuracy: 0.7126\n",
      "Epoch 471/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8590 - accuracy: 0.7202 - val_loss: 0.8678 - val_accuracy: 0.7128\n",
      "Epoch 472/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8581 - accuracy: 0.7203 - val_loss: 0.8670 - val_accuracy: 0.7130\n",
      "Epoch 473/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8572 - accuracy: 0.7209 - val_loss: 0.8661 - val_accuracy: 0.7132\n",
      "Epoch 474/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8563 - accuracy: 0.7209 - val_loss: 0.8652 - val_accuracy: 0.7135\n",
      "Epoch 475/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8554 - accuracy: 0.7211 - val_loss: 0.8643 - val_accuracy: 0.7136\n",
      "Epoch 476/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8545 - accuracy: 0.7213 - val_loss: 0.8635 - val_accuracy: 0.7138\n",
      "Epoch 477/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8536 - accuracy: 0.7216 - val_loss: 0.8626 - val_accuracy: 0.7139\n",
      "Epoch 478/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8527 - accuracy: 0.7214 - val_loss: 0.8618 - val_accuracy: 0.7143\n",
      "Epoch 479/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8519 - accuracy: 0.7219 - val_loss: 0.8609 - val_accuracy: 0.7145\n",
      "Epoch 480/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8510 - accuracy: 0.7221 - val_loss: 0.8600 - val_accuracy: 0.7148\n",
      "Epoch 481/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8501 - accuracy: 0.7222 - val_loss: 0.8592 - val_accuracy: 0.7149\n",
      "Epoch 482/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8493 - accuracy: 0.7223 - val_loss: 0.8583 - val_accuracy: 0.7152\n",
      "Epoch 483/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8484 - accuracy: 0.7224 - val_loss: 0.8575 - val_accuracy: 0.7154\n",
      "Epoch 484/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8476 - accuracy: 0.7228 - val_loss: 0.8567 - val_accuracy: 0.7156\n",
      "Epoch 485/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8467 - accuracy: 0.7228 - val_loss: 0.8558 - val_accuracy: 0.7157\n",
      "Epoch 486/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8459 - accuracy: 0.7228 - val_loss: 0.8550 - val_accuracy: 0.7158\n",
      "Epoch 487/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8450 - accuracy: 0.7233 - val_loss: 0.8542 - val_accuracy: 0.7161\n",
      "Epoch 488/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8442 - accuracy: 0.7232 - val_loss: 0.8533 - val_accuracy: 0.7163\n",
      "Epoch 489/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8433 - accuracy: 0.7234 - val_loss: 0.8525 - val_accuracy: 0.7163\n",
      "Epoch 490/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8425 - accuracy: 0.7237 - val_loss: 0.8517 - val_accuracy: 0.7163\n",
      "Epoch 491/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8416 - accuracy: 0.7236 - val_loss: 0.8508 - val_accuracy: 0.7163\n",
      "Epoch 492/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8408 - accuracy: 0.7237 - val_loss: 0.8500 - val_accuracy: 0.7163\n",
      "Epoch 493/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8400 - accuracy: 0.7238 - val_loss: 0.8492 - val_accuracy: 0.7168\n",
      "Epoch 494/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8392 - accuracy: 0.7244 - val_loss: 0.8484 - val_accuracy: 0.7170\n",
      "Epoch 495/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8383 - accuracy: 0.7243 - val_loss: 0.8476 - val_accuracy: 0.7171\n",
      "Epoch 496/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8375 - accuracy: 0.7246 - val_loss: 0.8468 - val_accuracy: 0.7172\n",
      "Epoch 497/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8367 - accuracy: 0.7243 - val_loss: 0.8460 - val_accuracy: 0.7171\n",
      "Epoch 498/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8359 - accuracy: 0.7248 - val_loss: 0.8452 - val_accuracy: 0.7171\n",
      "Epoch 499/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8351 - accuracy: 0.7247 - val_loss: 0.8444 - val_accuracy: 0.7173\n",
      "Epoch 500/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8343 - accuracy: 0.7249 - val_loss: 0.8436 - val_accuracy: 0.7176\n",
      "Epoch 501/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8335 - accuracy: 0.7251 - val_loss: 0.8428 - val_accuracy: 0.7178\n",
      "Epoch 502/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8326 - accuracy: 0.7254 - val_loss: 0.8420 - val_accuracy: 0.7179\n",
      "Epoch 503/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8318 - accuracy: 0.7254 - val_loss: 0.8412 - val_accuracy: 0.7179\n",
      "Epoch 504/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8310 - accuracy: 0.7257 - val_loss: 0.8404 - val_accuracy: 0.7181\n",
      "Epoch 505/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8303 - accuracy: 0.7256 - val_loss: 0.8397 - val_accuracy: 0.7183\n",
      "Epoch 506/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8295 - accuracy: 0.7258 - val_loss: 0.8389 - val_accuracy: 0.7188\n",
      "Epoch 507/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8287 - accuracy: 0.7258 - val_loss: 0.8381 - val_accuracy: 0.7185\n",
      "Epoch 508/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8279 - accuracy: 0.7261 - val_loss: 0.8373 - val_accuracy: 0.7184\n",
      "Epoch 509/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8271 - accuracy: 0.7261 - val_loss: 0.8366 - val_accuracy: 0.7187\n",
      "Epoch 510/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8263 - accuracy: 0.7263 - val_loss: 0.8358 - val_accuracy: 0.7188\n",
      "Epoch 511/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8255 - accuracy: 0.7264 - val_loss: 0.8350 - val_accuracy: 0.7191\n",
      "Epoch 512/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8248 - accuracy: 0.7266 - val_loss: 0.8343 - val_accuracy: 0.7195\n",
      "Epoch 513/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8240 - accuracy: 0.7268 - val_loss: 0.8335 - val_accuracy: 0.7195\n",
      "Epoch 514/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8232 - accuracy: 0.7268 - val_loss: 0.8328 - val_accuracy: 0.7197\n",
      "Epoch 515/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8225 - accuracy: 0.7271 - val_loss: 0.8320 - val_accuracy: 0.7197\n",
      "Epoch 516/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8217 - accuracy: 0.7271 - val_loss: 0.8313 - val_accuracy: 0.7198\n",
      "Epoch 517/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8209 - accuracy: 0.7274 - val_loss: 0.8305 - val_accuracy: 0.7201\n",
      "Epoch 518/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8202 - accuracy: 0.7273 - val_loss: 0.8298 - val_accuracy: 0.7202\n",
      "Epoch 519/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8194 - accuracy: 0.7276 - val_loss: 0.8290 - val_accuracy: 0.7205\n",
      "Epoch 520/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8187 - accuracy: 0.7276 - val_loss: 0.8283 - val_accuracy: 0.7208\n",
      "Epoch 521/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8179 - accuracy: 0.7279 - val_loss: 0.8275 - val_accuracy: 0.7209\n",
      "Epoch 522/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8172 - accuracy: 0.7280 - val_loss: 0.8268 - val_accuracy: 0.7212\n",
      "Epoch 523/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8164 - accuracy: 0.7282 - val_loss: 0.8261 - val_accuracy: 0.7212\n",
      "Epoch 524/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8157 - accuracy: 0.7282 - val_loss: 0.8254 - val_accuracy: 0.7217\n",
      "Epoch 525/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8150 - accuracy: 0.7284 - val_loss: 0.8246 - val_accuracy: 0.7222\n",
      "Epoch 526/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8142 - accuracy: 0.7285 - val_loss: 0.8239 - val_accuracy: 0.7219\n",
      "Epoch 527/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8135 - accuracy: 0.7287 - val_loss: 0.8232 - val_accuracy: 0.7218\n",
      "Epoch 528/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8128 - accuracy: 0.7286 - val_loss: 0.8225 - val_accuracy: 0.7218\n",
      "Epoch 529/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8120 - accuracy: 0.7290 - val_loss: 0.8217 - val_accuracy: 0.7220\n",
      "Epoch 530/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8113 - accuracy: 0.7292 - val_loss: 0.8210 - val_accuracy: 0.7223\n",
      "Epoch 531/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8106 - accuracy: 0.7290 - val_loss: 0.8203 - val_accuracy: 0.7228\n",
      "Epoch 532/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8099 - accuracy: 0.7294 - val_loss: 0.8196 - val_accuracy: 0.7228\n",
      "Epoch 533/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8091 - accuracy: 0.7294 - val_loss: 0.8189 - val_accuracy: 0.7230\n",
      "Epoch 534/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8084 - accuracy: 0.7295 - val_loss: 0.8182 - val_accuracy: 0.7231\n",
      "Epoch 535/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8077 - accuracy: 0.7296 - val_loss: 0.8175 - val_accuracy: 0.7234\n",
      "Epoch 536/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8070 - accuracy: 0.7300 - val_loss: 0.8168 - val_accuracy: 0.7234\n",
      "Epoch 537/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8063 - accuracy: 0.7300 - val_loss: 0.8161 - val_accuracy: 0.7239\n",
      "Epoch 538/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8056 - accuracy: 0.7302 - val_loss: 0.8154 - val_accuracy: 0.7243\n",
      "Epoch 539/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8049 - accuracy: 0.7305 - val_loss: 0.8147 - val_accuracy: 0.7245\n",
      "Epoch 540/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8042 - accuracy: 0.7304 - val_loss: 0.8140 - val_accuracy: 0.7247\n",
      "Epoch 541/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8035 - accuracy: 0.7304 - val_loss: 0.8134 - val_accuracy: 0.7247\n",
      "Epoch 542/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8028 - accuracy: 0.7310 - val_loss: 0.8127 - val_accuracy: 0.7249\n",
      "Epoch 543/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8021 - accuracy: 0.7309 - val_loss: 0.8120 - val_accuracy: 0.7251\n",
      "Epoch 544/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8014 - accuracy: 0.7312 - val_loss: 0.8113 - val_accuracy: 0.7252\n",
      "Epoch 545/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8007 - accuracy: 0.7314 - val_loss: 0.8106 - val_accuracy: 0.7257\n",
      "Epoch 546/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.8000 - accuracy: 0.7313 - val_loss: 0.8100 - val_accuracy: 0.7258\n",
      "Epoch 547/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7994 - accuracy: 0.7316 - val_loss: 0.8093 - val_accuracy: 0.7258\n",
      "Epoch 548/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7987 - accuracy: 0.7318 - val_loss: 0.8086 - val_accuracy: 0.7259\n",
      "Epoch 549/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7980 - accuracy: 0.7320 - val_loss: 0.8080 - val_accuracy: 0.7261\n",
      "Epoch 550/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7973 - accuracy: 0.7320 - val_loss: 0.8073 - val_accuracy: 0.7262\n",
      "Epoch 551/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7966 - accuracy: 0.7324 - val_loss: 0.8066 - val_accuracy: 0.7264\n",
      "Epoch 552/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7960 - accuracy: 0.7323 - val_loss: 0.8060 - val_accuracy: 0.7265\n",
      "Epoch 553/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7953 - accuracy: 0.7326 - val_loss: 0.8053 - val_accuracy: 0.7268\n",
      "Epoch 554/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7946 - accuracy: 0.7323 - val_loss: 0.8047 - val_accuracy: 0.7270\n",
      "Epoch 555/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7940 - accuracy: 0.7327 - val_loss: 0.8040 - val_accuracy: 0.7270\n",
      "Epoch 556/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7933 - accuracy: 0.7328 - val_loss: 0.8034 - val_accuracy: 0.7271\n",
      "Epoch 557/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7927 - accuracy: 0.7326 - val_loss: 0.8027 - val_accuracy: 0.7272\n",
      "Epoch 558/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7920 - accuracy: 0.7329 - val_loss: 0.8021 - val_accuracy: 0.7278\n",
      "Epoch 559/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7914 - accuracy: 0.7332 - val_loss: 0.8014 - val_accuracy: 0.7278\n",
      "Epoch 560/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7907 - accuracy: 0.7334 - val_loss: 0.8008 - val_accuracy: 0.7278\n",
      "Epoch 561/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7901 - accuracy: 0.7337 - val_loss: 0.8002 - val_accuracy: 0.7279\n",
      "Epoch 562/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7894 - accuracy: 0.7336 - val_loss: 0.7995 - val_accuracy: 0.7281\n",
      "Epoch 563/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7888 - accuracy: 0.7337 - val_loss: 0.7989 - val_accuracy: 0.7287\n",
      "Epoch 564/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7881 - accuracy: 0.7341 - val_loss: 0.7983 - val_accuracy: 0.7288\n",
      "Epoch 565/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7875 - accuracy: 0.7338 - val_loss: 0.7976 - val_accuracy: 0.7289\n",
      "Epoch 566/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7868 - accuracy: 0.7341 - val_loss: 0.7970 - val_accuracy: 0.7290\n",
      "Epoch 567/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7862 - accuracy: 0.7342 - val_loss: 0.7964 - val_accuracy: 0.7290\n",
      "Epoch 568/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7856 - accuracy: 0.7344 - val_loss: 0.7957 - val_accuracy: 0.7290\n",
      "Epoch 569/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7849 - accuracy: 0.7345 - val_loss: 0.7951 - val_accuracy: 0.7292\n",
      "Epoch 570/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7843 - accuracy: 0.7345 - val_loss: 0.7945 - val_accuracy: 0.7293\n",
      "Epoch 571/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7837 - accuracy: 0.7346 - val_loss: 0.7939 - val_accuracy: 0.7295\n",
      "Epoch 572/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7831 - accuracy: 0.7349 - val_loss: 0.7933 - val_accuracy: 0.7297\n",
      "Epoch 573/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7824 - accuracy: 0.7348 - val_loss: 0.7927 - val_accuracy: 0.7297\n",
      "Epoch 574/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7818 - accuracy: 0.7351 - val_loss: 0.7921 - val_accuracy: 0.7297\n",
      "Epoch 575/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7812 - accuracy: 0.7352 - val_loss: 0.7915 - val_accuracy: 0.7298\n",
      "Epoch 576/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7806 - accuracy: 0.7354 - val_loss: 0.7909 - val_accuracy: 0.7297\n",
      "Epoch 577/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7800 - accuracy: 0.7353 - val_loss: 0.7903 - val_accuracy: 0.7300\n",
      "Epoch 578/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7794 - accuracy: 0.7353 - val_loss: 0.7896 - val_accuracy: 0.7301\n",
      "Epoch 579/600\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.7788 - accuracy: 0.7356 - val_loss: 0.7890 - val_accuracy: 0.7303\n",
      "Epoch 580/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7782 - accuracy: 0.7355 - val_loss: 0.7885 - val_accuracy: 0.7307\n",
      "Epoch 581/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7776 - accuracy: 0.7359 - val_loss: 0.7879 - val_accuracy: 0.7308\n",
      "Epoch 582/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7770 - accuracy: 0.7359 - val_loss: 0.7873 - val_accuracy: 0.7309\n",
      "Epoch 583/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7764 - accuracy: 0.7362 - val_loss: 0.7867 - val_accuracy: 0.7312\n",
      "Epoch 584/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7758 - accuracy: 0.7361 - val_loss: 0.7861 - val_accuracy: 0.7313\n",
      "Epoch 585/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7752 - accuracy: 0.7365 - val_loss: 0.7855 - val_accuracy: 0.7312\n",
      "Epoch 586/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7746 - accuracy: 0.7367 - val_loss: 0.7849 - val_accuracy: 0.7314\n",
      "Epoch 587/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7740 - accuracy: 0.7368 - val_loss: 0.7843 - val_accuracy: 0.7316\n",
      "Epoch 588/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7734 - accuracy: 0.7370 - val_loss: 0.7838 - val_accuracy: 0.7318\n",
      "Epoch 589/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7728 - accuracy: 0.7370 - val_loss: 0.7832 - val_accuracy: 0.7318\n",
      "Epoch 590/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7722 - accuracy: 0.7372 - val_loss: 0.7826 - val_accuracy: 0.7319\n",
      "Epoch 591/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7716 - accuracy: 0.7372 - val_loss: 0.7820 - val_accuracy: 0.7322\n",
      "Epoch 592/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7711 - accuracy: 0.7376 - val_loss: 0.7815 - val_accuracy: 0.7323\n",
      "Epoch 593/600\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.7705 - accuracy: 0.7378 - val_loss: 0.7809 - val_accuracy: 0.7324\n",
      "Epoch 594/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7699 - accuracy: 0.7376 - val_loss: 0.7803 - val_accuracy: 0.7321\n",
      "Epoch 595/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7693 - accuracy: 0.7377 - val_loss: 0.7798 - val_accuracy: 0.7324\n",
      "Epoch 596/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7687 - accuracy: 0.7378 - val_loss: 0.7792 - val_accuracy: 0.7326\n",
      "Epoch 597/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7682 - accuracy: 0.7380 - val_loss: 0.7786 - val_accuracy: 0.7327\n",
      "Epoch 598/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7676 - accuracy: 0.7382 - val_loss: 0.7781 - val_accuracy: 0.7331\n",
      "Epoch 599/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7670 - accuracy: 0.7383 - val_loss: 0.7775 - val_accuracy: 0.7332\n",
      "Epoch 600/600\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.7665 - accuracy: 0.7384 - val_loss: 0.7770 - val_accuracy: 0.7334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================== TEST ==============================\n",
      "loss: 0.7782276665687561\n",
      "accuracy: 0.7289000153541565\n",
      "===============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from MLANN import *\n",
    "\n",
    "'''\n",
    "Multilayers Neural Network with Keras\n",
    "Cross Entropy is used for the loss function,\n",
    "Stochasitc Gradient Descent is used for the optimizer\n",
    "Accuracy is used to measure the model accuracy\n",
    "'''     \n",
    "### Hyper Parameters used to adjust the result ###\n",
    "hiddens = [[500,100],[300,50],[500,300,100]] # <---- Hyperparameters (Hidden Layer Parameters)\n",
    "batch_size = [600,5000,10000] # <---- Hyperparameters (Batch Size)\n",
    "\n",
    "activation = 'sigmoid' # <---- Hyperparameters (Activation Function)\n",
    "epoch = 100 # <---- Hyperparameters (Epochs)\n",
    "\n",
    "### Data ###\n",
    "X,y = get_data(PATH, kind='train', norm_size=255)\n",
    "val_X,val_y = get_validation_data(X,y,0.2)      ### use 20% of the training data for validation ###\n",
    "test_X,test_y = get_data(PATH, kind='t10k', norm_size=255)\n",
    "\n",
    "\n",
    "### Neural Network Model with Keras ###\n",
    "mlann = MLANN(X.shape[1],hiddens[1],10,activation)\n",
    "mlann.__build_keras_ann__()\n",
    "mlann.__train__(X,y,(val_X,val_y),epoch,batch_size[1])\n",
    "\n",
    "mlann.__test__(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN import *\n",
    "\n",
    "def get_validation_data(X,y,validation_percentage):\n",
    "    validation_X = []\n",
    "    validation_y = []\n",
    "    random_index = np.random.permutation(len(X))\n",
    "    val_size = int(len(X) * validation_percentage)\n",
    "    for i in range(val_size):\n",
    "        validation_X.append(X[random_index[i]])\n",
    "        validation_y.append(y[random_index[i]])\n",
    "    return np.array(validation_X), np.array(validation_y)\n",
    "\n",
    "'''\n",
    "This function initiazes the default layer settings for each type of layers\n",
    "So everytime a new layer is created there will not be repetitive coding\n",
    "'''\n",
    "def get_partial():\n",
    "    def_conv2d = partial(Conv2d_Parameters,filters_=10,kernel_size_=3,strides_=(1,1),padding_='SAME',activation_='relu')\n",
    "    def_pool = partial(Pooling_Parameters,pooling_type_='max', pooling_size_=2)\n",
    "    def_dense = partial(Dense_Parameters,units_=64, activation_='relu')\n",
    "    return def_conv2d, def_pool, def_dense\n",
    "\n",
    "'''\n",
    "Parameters for the CNN model\n",
    "These parameters can be adjusted for a better model\n",
    "'''\n",
    "def get_cnn_params():\n",
    "    def_conv2d, def_pool, def_dense = get_partial()\n",
    "    cnn_input = def_conv2d()\n",
    "    cnn_convs = [def_conv2d()]\n",
    "    cnn_pools = [def_pool()]\n",
    "    cnn_hids = [def_dense()]\n",
    "    cnn_output = def_dense(units_=10,activation_='softmax')\n",
    "    return cnn_input, cnn_convs, cnn_pools, cnn_hids, cnn_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Convolutional Neural Network with Keras\n",
    "This class creates a convolutional Neural Network with that consists:\n",
    "input layaer, convolutional layers, pooling layers, falltened Neural Network Layers, and output layer\n",
    "'''\n",
    "### Hyper Parameters used to adjust the result ###\n",
    "### More Hyper parameters can be adjusted from 'get_partial' function on line 171 ###\n",
    "epoch = 1000 # <---- Hyperparameters (Epochs)\n",
    "batch_size = 1000 # <---- Hyperparameters (Batch Size)\n",
    "### The parameter classes for CNN class ###\n",
    "cnn_input, cnn_convs, cnn_pools, cnn_hids, cnn_output = get_cnn_params()\n",
    "\n",
    "\n",
    "### Data ###\n",
    "X,y = get_data(PATH, kind='train', norm_size=255)\n",
    "np.random.shuffle(X);np.random.shuffle(y)\n",
    "val_X,val_y = get_validation_data(X,y,0.2)      ### use 20% of the training data for validation ###\n",
    "X = np.reshape(X,(X.shape[0],28,28,1))          ### Reshape the flattened image to 3D ###\n",
    "val_X = np.reshape(val_X,(val_X.shape[0],28,28,1))\n",
    "test_X,test_y = get_data(PATH, kind='t10k', norm_size=255)\n",
    "test_X = np.reshape(test_X,(test_X.shape[0],28,28,1))\n",
    "\n",
    "\n",
    "### Convolutional Neural Network ###\n",
    "cnn = CNN(cnn_input, cnn_convs, cnn_pools, cnn_hids, cnn_output)\n",
    "cnn.__build_cnn_model__()\n",
    "cnn.__train__(X,y,(val_X,val_y),epoch,batch_size)\n",
    "\n",
    "cnn.__test__(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
